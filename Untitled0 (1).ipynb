{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CvVqi9SFKUs"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d shubhamgoel27/dermnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS-xkZ7FFNHk",
        "outputId": "d8c42042-1d53-4bbb-a8f3-c7ba760ff7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/shubhamgoel27/dermnet\n",
            "License(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n",
            "Downloading dermnet.zip to /content\n",
            " 98% 1.68G/1.72G [00:13<00:00, 230MB/s]\n",
            "100% 1.72G/1.72G [00:14<00:00, 131MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"dermnet.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"dermnet\")"
      ],
      "metadata": {
        "id": "pI_CmBDZFRXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Conv2D ,Dense, Dropout, MaxPooling2D,Flatten,BatchNormalization,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "metadata": {
        "id": "RUoJNTMbFTIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/dermnet\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "test_dir = os.path.join(base_dir, \"test\")"
      ],
      "metadata": {
        "id": "BlGUPUp8FU4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "def process_resnet50(image, label):\n",
        "  # Cast to float32 before preprocessing (recommended for all models)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  # Apply ResNet50-specific preprocessing (subtracts ImageNet mean)\n",
        "  image = preprocess_input(image)\n",
        "  return image, label\n",
        "\n",
        "# Re-map your datasets with the correct processing function\n",
        "train = train_dir.map(process_resnet50)\n",
        "test = test_dir.map(process_resnet50)\n",
        "\n",
        "# The rest of your model code remains the same:\n",
        "# model.fit(train, validation_data=test, epochs=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "gHeREVvaFWwY",
        "outputId": "a9270bca-1566-45f7-b38a-8223ab0a0c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'map'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-155488176.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Re-map your datasets with the correct processing function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_resnet50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_resnet50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'map'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define Augmentation Pipeline\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    keras.layers.RandomRotation(0.2), # Rotate up to 20%\n",
        "    keras.layers.RandomZoom(0.2),      # Zoom up to 20%\n",
        "    keras.layers.RandomContrast(0.1), # Small contrast change\n",
        "  ],\n",
        "  name=\"data_augmentation\"\n",
        ")\n",
        "\n",
        "# 2. Function to apply augmentation\n",
        "def augment_and_process(image, label):\n",
        "    # Apply augmentation (only during training)\n",
        "    image = data_augmentation(image, training=True)\n",
        "    # Apply ResNet50-specific processing\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "# 3. Create the augmented and processed training dataset\n",
        "train_augmented = data_train.map(augment_and_process)\n",
        "\n",
        "# 4. Use the non-augmented, processed test dataset\n",
        "test_processed = data_test.map(process_resnet50)\n",
        "\n",
        "# Now use train_augmented and test_processed for model.fit\n",
        "# model.fit(train_augmented, validation_data=test_processed, epochs=40)"
      ],
      "metadata": {
        "id": "iV7f5RvAFb0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "k6X02n0WFfKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,  # Remove original classifier\n",
        "    input_shape=(256, 256, 3)\n",
        ")\n",
        "base_model.trainable = False\n"
      ],
      "metadata": {
        "id": "6PedYwd0FiUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "#model.add(Dense(2048, activation='relu'))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "#model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(23, activation='softmax'))"
      ],
      "metadata": {
        "id": "tTDXTP9vFkUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-6),  # Lower LR because base model is frozen\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Pe1ZtxoTFmbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "BntTJzhRFoLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train, validation_data=test, epochs=40)"
      ],
      "metadata": {
        "id": "5mr-bKQHFqTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"skin_disease_model_new.h5\")"
      ],
      "metadata": {
        "id": "c2UyL0OWJFrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "dcpg4YEaMEQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= load_model('skin_disease_model.h5')\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "img_path = \"ACNE_IMAGE.jpg\"\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.resize(img, (256, 256))\n",
        "\n",
        "img = np.expand_dims(img, axis=0)\n"
      ],
      "metadata": {
        "id": "Vdx14aA4MPx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "predictions = model.predict(img)\n",
        "\n",
        "# Get class index\n",
        "predicted_class = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "print(\"Predicted class index:\", predicted_class)\n"
      ],
      "metadata": {
        "id": "ctPQJECcU4IO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}